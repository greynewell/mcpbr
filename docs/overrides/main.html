{% extends "base.html" %}

{% block extrahead %}
  {{ super() }}

  {# Open Graph Meta Tags #}
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="mcpbr Documentation" />
  <meta property="og:title" content="{{ page.title }} - mcpbr Documentation" />
  <meta property="og:url" content="{{ page.canonical_url }}" />
  {% if page and page.meta and page.meta.description %}
  <meta property="og:description" content="{{ page.meta.description | e }}" />
  {% else %}
  <meta property="og:description" content="{{ config.site_description | e }}" />
  {% endif %}
  <meta property="og:image" content="https://mcpbr.org/assets/mcpbr-logo.jpg" />

  {# Twitter Card Meta Tags #}
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="{{ page.title }} - mcpbr Documentation" />
  {% if page and page.meta and page.meta.description %}
  <meta name="twitter:description" content="{{ page.meta.description | e }}" />
  {% else %}
  <meta name="twitter:description" content="{{ config.site_description | e }}" />
  {% endif %}
  <meta name="twitter:image" content="https://mcpbr.org/assets/mcpbr-logo.jpg" />

  {# Per-Page Meta Description from Frontmatter #}
  {% if page and page.meta and page.meta.description %}
  <meta name="description" content="{{ page.meta.description | e }}" />
  {% endif %}

  {# FAQ JSON-LD Structured Data #}
  {% if page and page.meta and page.meta.faq %}
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "FAQPage",
    "mainEntity": [
      {% for item in page.meta.faq %}
      {
        "@type": "Question",
        "name": "{{ item.q | e }}",
        "acceptedAnswer": {
          "@type": "Answer",
          "text": "{{ item.a | e }}"
        }
      }{% if not loop.last %},{% endif %}
      {% endfor %}
    ]
  }
  </script>
  {% endif %}

  {# HowTo JSON-LD Structured Data for Benchmark Pages #}
  {% if page and page.meta and page.meta.benchmark_howto %}
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "HowTo",
    "name": "{{ page.meta.benchmark_howto.name | e }}",
    "description": "{{ page.meta.benchmark_howto.description | e }}",
    "tool": {
      "@type": "SoftwareApplication",
      "name": "mcpbr"
    },
    "step": [
      {
        "@type": "HowToStep",
        "name": "Install mcpbr",
        "text": "Install mcpbr with pip install mcpbr"
      },
      {
        "@type": "HowToStep",
        "name": "Configure benchmark",
        "text": "Set benchmark: {{ page.meta.benchmark_howto.benchmark_id | e }} in your YAML config"
      },
      {
        "@type": "HowToStep",
        "name": "Run evaluation",
        "text": "Execute mcpbr run -c config.yaml --benchmark {{ page.meta.benchmark_howto.benchmark_id | e }}"
      }
    ]
  }
  </script>
  {% endif %}

  {# Software Application Structured Data for Home Page #}
  {% if page and (page.is_homepage or page.url == '.' or page.url == '') %}
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "SoftwareApplication",
    "name": "mcpbr",
    "applicationCategory": "DeveloperApplication",
    "operatingSystem": "Linux, macOS, Windows",
    "description": "Model Context Protocol Benchmark Runner - evaluate AI agents and MCP servers across 25+ benchmarks including SWE-bench, HumanEval, GSM8K, CyberGym, and more",
    "url": "https://mcpbr.org/",
    "downloadUrl": "https://pypi.org/project/mcpbr/",
    "softwareVersion": "0.4.5",
    "license": "https://opensource.org/licenses/MIT",
    "programmingLanguage": "Python",
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
  </script>
  {% endif %}
{% endblock %}
